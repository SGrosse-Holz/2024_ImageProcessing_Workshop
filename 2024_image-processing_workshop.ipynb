{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a80840-df9e-4ba0-b71e-6df49e0c115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running in Google Colab, uncomment and run the lines below\n",
    "# !git clone https://github.com/SGrosse-Holz/2024_ImageProcessing_Workshop\n",
    "# !pip install 2024_ImageProcessing_Workshop/bayesmsd-0.1.4-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb7d4e3-d0ce-4398-bb69-3303f9be2e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas trackpy noctiluca bayesmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928eb8df-cf1b-48bf-813e-7c4993e6351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "from pathlib import Path\n",
    "import io\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import trackpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import noctiluca as nl\n",
    "import bayesmsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f4ffaf-c9d1-45a5-b04b-e203cc8b9cf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Intro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65a59cfd-a0cd-48c3-a287-0c009226f6d4",
   "metadata": {},
   "source": [
    "As a relatively straight-forward example of live-cell imaging data, we study the dynamics of the chromatin fiber. Our \"virtual collaborator\" engineered a U2OS cell line where histone H2B is (sparsely) labelled with a fluorescent marker. Imaging their cells under a fluorescent microscope, they got a few nice movies that might look something like this:\n",
    "<div>\n",
    "<img src=\"graphics/movie_gif.gif\" width=\"300\" alt=\"animation of the original movie\"/>\n",
    "</div>\n",
    "<font size=\"1\">\n",
    "Movie acquired by SGH, Coulon lab @ Institute Curie, 2022\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee6b866-5833-4115-a4fe-ca7d02b0726a",
   "metadata": {},
   "source": [
    "**Cool! What and how do we learn from this?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a918a-07df-4d18-ade5-6e7fc57c4e48",
   "metadata": {},
   "source": [
    "In dealing with data like the movie above, we usually follow a three step procedure:\n",
    "+ **localize** individual fluorophores in the movie\n",
    "+ **link** localizations from different frames together in coherent trajectories\n",
    "+ **analyze** those trajectories to understand the underlying physics/biology\n",
    "\n",
    "This workshop will lead you through each of these three steps in order. Let's get into it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de046c-96bd-423c-b697-e67e7de19657",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Localizing fluorescent spots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce38d21e-b667-44ed-acde-a3438bccaa91",
   "metadata": {},
   "source": [
    "![raw movie frame](graphics/localize0.png)\n",
    "![movie frame with localizations](graphics/localize1.png)\n",
    "\n",
    "The goal of this section is illustrated by the stills above: identify the locations of the individual fluorescent markers in each frame of our movie. For this workshop, we will use the ImageJ plug-in \"ThunderSTORM\", which takes a physics-minded approach to this task and is thus very well suited for single molecule experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36334c1a-363d-4221-8a60-b587aa596429",
   "metadata": {},
   "source": [
    "### Software"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ab3d6-690e-4f9e-a89e-5c86485d3e4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "This section of the tutorial relies on software running locally on your machine. We will use\n",
    "+ [Fiji/ImageJ: the de facto standard image processing tool in life sciences](https://imagej.net/software/fiji/downloads)\n",
    "+ [ThunderSTORM: a plug-in for particle localization](https://zitmen.github.io/thunderstorm/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf24f45-b372-4483-b6be-aabfa275226f",
   "metadata": {},
   "source": [
    "#### Installation instructions (please do this before the workshop!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cfa839-bb62-4417-a1a9-ca92aa5cc011",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "+ **download Fiji**: go to the Fiji website linked above and download the right version for your OS. This will be a zip-compressed folder.\n",
    "  - **extract** the folder to a location in your user space (e.g. under Windows the recommended location is `C:\\Users\\<your user>\\Fiji`; note that the website warns against installing to `C:\\Program Files`, since Fiji might not have write permissions there). We will assume that you chose the location `<path>\\Fiji`.\n",
    "  - **locate Fiji's plug-in folder**; it should be at `<path>\\Fiji\\Fiji.app\\plugins`. It should already contain a whole library of `.jar` files\n",
    "+ go to the link for ThunderSTORM; click the \"download ThunderSTORM\" button on the top left. You will be redirected to GitHub.\n",
    "  - **download the file `Thunder_STORM.jar`** and\n",
    "  - **place it in Fiji's plug-in folder**\n",
    "+ **start Fiji** by running the executable found in `<path>\\Fiji\\Fiji.app`. On Windows, it is called `ImageJ-win64.exe` (not \"Fiji\"!)\n",
    "  - check that the menu `Plugins > ThunderSTORM` exists\n",
    "+ create a new directory somewhere in your user space, which we will use as working directory for this tutorial. Place the tutorial data (`localization_demo_U2OS_H2B_JF549.tif`) in this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b19683-de2f-4249-ab42-17415d4ed5c3",
   "metadata": {},
   "source": [
    "## Open the movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa3ea0-31a1-4cc2-bd51-25583f3a088c",
   "metadata": {},
   "source": [
    "You can drag-and-drop the movie (`localization_demo_U2OS_H2B_JF549.tif`) into Fiji; alternatively, use `File > Open` or `Ctrl-O`. Once the movie pops up, you can press the `+`/`-` keys to grow/shrink the window as you like. You will probably want to adjust the contrast a little, so go to `Image > Adjust > Brightness/Contrast` (or `Ctrl-Shift-C`) to bring up the corresponding dialog. You can play with the settings, or just hit the `Auto` button, which usually gives a decent picture. Note that we are only adjusting the visualization, we are not changing the data in the movie!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aea0e6-95a1-4f77-a7e2-9e8d81f1174b",
   "metadata": {},
   "source": [
    "You can use the slider on the bottom to scroll through the movie and get a first impression of what your data actually looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b445b3-4ceb-4cee-ac61-63ac3a15328b",
   "metadata": {},
   "source": [
    "### Two short exercises to familiarize yourself with Fiji and our movie"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c6065d7-41ed-41d0-81af-baa8d023e56b",
   "metadata": {},
   "source": [
    "**Task 1**: Can you measure the pixel size?\n",
    "\n",
    "![A line at the bottom of the Fiji window gives live info about the current cursor position](graphics/values.png)\n",
    "\n",
    "At the bottom of the main window, you have a readout of your current cursor position in the movie. `x` and `y` coordinates are given in μm (pixels).\n",
    "\n",
    "Zoom in or out of the image with the `+`/`-` keys until you can clearly see individual pixels. Use the reported absolute positions of a few adjacent pixels to estimate the pixel size in μm. The code below might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d307245-2eae-4aad-ac05-922db0113c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [15.83, 15.96, ...]\n",
    "pixelsize_um = np.mean(np.diff(locations))\n",
    "print(f\"Hand-estimated pixel size:     {pixelsize_um:.4f} μm\")\n",
    "print( \"True pixel size in this movie: 0.1287 μm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4cc72-f9aa-4cfa-b89d-38c6a8db6992",
   "metadata": {},
   "source": [
    "**Task 2**: How wide is a point-spread function?\n",
    "\n",
    "The spots you see in the movie are (for the most part) single fluorescent molecules. However, due to the wave nature of light, they appear not as single points (or pixels), but as finite size \"blobs\". This blob is called a \"point spread function (PSF)\" and determines the minimum distance that two particles must have, such that we can still distinguish them; this is known as the *diffraction limit*.\n",
    "\n",
    "Look at a few of the spots in the movie; what would you say is their average diameter (in pixels)? What is that in μm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e935b5d-ddad-4e25-a68f-a48ef39b8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter_px = ...\n",
    "diameter_um = diameter_px * pixelsize_um\n",
    "print(f\"PSF Diameter: {diameter_um:.3f} μm\")\n",
    "print(f\"PSF Radius:     {500*diameter_um:.0f} nm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0822d5-21b8-49af-b9e7-a38f731ae54f",
   "metadata": {},
   "source": [
    "**Task 3**: Emission wave length from PSF\n",
    "\n",
    "We expect the PSF to have a diameter of $d = \\lambda/\\mathrm{NA}$, where the \"numerical aperture\" $\\mathrm{NA}$ is a characteristic of the microscope objective; for our example movie, $\\mathrm{NA} = 1.4$. Can you estimate the emission wave length $\\lambda$ of the fluorophore? Can you tell how good your estimate is?\n",
    "\n",
    "<font size=\"1\">\n",
    "Hint: the fluorophore is called \"JF549\"\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e26f1c-e11f-4be6-ac77-782590b06b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "NA = 1.4\n",
    "wavelength_nm = 1e3 * diameter_um * NA\n",
    "print(f\"Estimated emission wavelength: {wavelength_nm:.0f} nm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bd5c6c-a520-44e6-8fac-e6e3abaef3e4",
   "metadata": {},
   "source": [
    "## Set up for spot detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7571ffe8-ad08-4b9d-a04f-ba490d0f7414",
   "metadata": {},
   "source": [
    "![The freehand selection tool in Fiji GUI](graphics/roi_selector.png)\n",
    "\n",
    "Our movie contains some fluorescent accumulation outside the nucleus, which we would like to exclude from the localization procedure. Use the freehand selection tool to draw an ROI (\"region of interest\") around the nucleus. Once you have your ROI, you can scroll through the movie to check that the nucleus does not leave this region over the course of the movie.\n",
    "\n",
    "![An example ROI](graphics/roi.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aef2d0ee-8b4b-4ee4-b48c-49e0c0a963a3",
   "metadata": {},
   "source": [
    "Start ThunderSTORM through the Fiji menu `Plugins > ThunderSTORM > Run analysis`. In the dialog that appears, click on <button>Camera setup</button> at the top and enter the following values:\n",
    "\n",
    "![ThunderSTORM camera settings:  Pixel size [nm] = 128.7  ||  Photoelectrons per A/D count = 8  ||  Base level [A/D counts] = 450  ||  EM gain = 30](graphics/camera_setup.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2c664-c33f-48d1-b58a-84a8970e8db0",
   "metadata": {},
   "source": [
    "These parameters allow ThunderSTORM to work in physical units: nanometers and photon count.\n",
    "\n",
    "The latter, in fact, we rarely really use; setting the associated parameters (i.e. everything beyond pixel size) to wrong values therefore [is not a big issue](https://github.com/zitmen/thunderstorm/wiki/Guidelines-for-the-choice-of-parameters#camera) and it would also be fine to leave them at their default value (unless you want to analyze e.g. the localization uncertainty reported by ThunderSTORM; we will come back to this in the Analysis section of the workshop)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f02b815c-64a6-4fe7-acd2-214f0c7ff9ff",
   "metadata": {},
   "source": [
    "Finally, enter the following settings in the main ThunderSTORM dialog:\n",
    "\n",
    "![ThunderSTORM localization setup  ||  Wavelet filter, order=3, scale=2.0  ||  Local maximum in 8-neighborhood, peak intensity threshold = 2.0*std(Wave.F1)  ||  PSF: Integrated Gaussian (weighted least squares), fitting radius=3px, initial sigma=1.0, no multi-emitter fitting  ||  No Renderer](graphics/thunderstorm_setup.png)\n",
    "\n",
    "You can hit <button>Preview</button> at the bottom to check where you would localize particles in the current frame of the movie with these settings. This is generally useful to tune the different parameters a little bit to your specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00353883-dc3e-40d7-ad06-01ddf20caaf8",
   "metadata": {},
   "source": [
    "ThunderSTORM takes a three-step approach to finding particle coordinates in a frame:\n",
    "+ **filter the image** to suppress noise and make \"PSF-sized\" structures stand out; note that this requires knowing what \"PSF-sized\" means. This is encoded in the parameters given to the different methods available for this step. The filtered image pops up along with the localizations when you generate the preview.\n",
    "+ **identify particle candidates** in the filtered image. The filtering suppresses noise, so now we can just search for local maxima as our candidates for each particle.\n",
    "+ **refine the position estimate** from the raw data. Now that we have candidates for our particle locations, we can locally optimize the position estimates. Generally there are two approaches: fit the PSF, or simply determine the centroid of the candidate \"blob\". Generally speaking, fitting PSFs is appropriate only for diffraction limited (i.e. small) probes such as single molecules, while for larger probes (such as fluorescent arrays) one should switch to centroid localization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64524c23-23b2-4d2a-a761-0a25feda444b",
   "metadata": {},
   "source": [
    "**Task 4**: the \"Peak intensity threshold\" parameter in the \"Approximate localization of molecules\" step controls the prominence over background that a spot needs to have to be detected as a candidate for localization. Vary the numerical prefactor and observe the effect on the localizations you get in Preview. Can you determine a reasonable setting for this parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972310ad-1aee-47e1-acd1-3fef4233386f",
   "metadata": {},
   "source": [
    "## Find all spots!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17245a-0763-49e8-b8eb-9c63989687de",
   "metadata": {},
   "source": [
    "When you are happy with the parameter settings, hit <button>Ok</button> on the ThunderSTORM configuration dialog to run the spot detection on the whole movie (*if a log window pops up complaining about the camera base level, it can just be ignored and/or closed*). You should get a table with all the localizations; simultaneously, the localizations will be overlaid on the movie, so you can also scroll through there to check how well we did."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ddf730f-829a-4489-a9d3-57cd5841ad5e",
   "metadata": {},
   "source": [
    "![Table with ThunderSTORM localizations](graphics/localizations.png)\n",
    "\n",
    "The important columns in this table are\n",
    "+ **id**: a unique number for each localization\n",
    "+ **frame**: which frame this localization is in\n",
    "+ **x**, **y**: the absolute position of this localization\n",
    "+ **sigma**: the fitted standard deviation of the PSF. Compare these values to the PSF radius (radius, not diameter!) we estimated above.\n",
    "+ **intensity**: total photon count associated with this localization\n",
    "+ **offset**: background intensity; should be positive for \"real\" detections\n",
    "+ **uncertainty**: the uncertainty that ThunderSTORM associates with this location estimate of the fluorophore. This is a theoretical estimate derived from `sigma` and `intensity`; so if your camera calibration is off, you shouldn't trust this value too much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17deeccc-bef5-4890-968a-b6b1b9615421",
   "metadata": {},
   "source": [
    "Note that there seem to be some outliers, likely wrong localizations. E.g. localization #8 reports a sigma of 635 nm, which is noticeably larger than what we would expect for our single fluorophores. We would thus like to a) identify outliers and then b) filter them out of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eba623-19de-44d6-adbf-f0792b0add9d",
   "metadata": {},
   "source": [
    "**Task 5**: use <button>Plot histogram</button> at the bottom of the dialog to check the distributions of a few parameters; of special interest are `sigma`, `offset` and `uncertainty`. Identify outliers. Then, use the \"Filter\" tab at the bottom of the window to filter them out. \n",
    "\n",
    "Find a good filter criterion to clean up the data set; aim to be rather restrictive than permissive (the logic being that missing good localizations just makes you lose data; including bad localizations makes your data wrong).\n",
    "\n",
    "*Tip*: The entry in the \"Filter\" field should be a logical expression using the parameters from the table, e.g. one could write `(x > 8000 y < 12000) | sigma > 300` to filter for only those localizations that are either in the top right corner, OR have a large PSF standard deviation. Once you hit \"Apply\", the table as well as the overlay on the movie update, so you can see the effect of your filtering. You can also replot histograms to check the effects on the whole data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c2f768-492b-4492-972a-41256fc9cf8b",
   "metadata": {},
   "source": [
    "**Solution to Task 5**: if you think you have found a good filter criterion, feel free to use that. If you are unsure, enter the following in the \"Filter\" line: `sigma < 200 & uncertainty < 30`. Note that we lose quite a few localizations in the first frames of the movie, but reliably keep those that persist for longer times. Also note that upon replotting the histogram for \"offset\", all the zero-offset localizations are gone; those are usually mislocalizations (which we could also explicitly filter for)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "102e168b-5871-4176-8978-a522444c0734",
   "metadata": {},
   "source": [
    "Finally, use the \"Remove duplicates\" tab to filter out localizations that ended up on the same molecule. Use `sigma` as the threshold.\n",
    "\n",
    "![Removing duplicates](graphics/duplicates.png)\n",
    "\n",
    "Note the very bottom line, stating that this step removed 4 out of 5674 localizations; so we did not have many overlaps to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f1759-2149-45f3-a35e-bc7511c3ec26",
   "metadata": {},
   "source": [
    "## Save localizations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcaf14ce-bba4-4a5c-a337-1df0efdc40cd",
   "metadata": {},
   "source": [
    "We're done! Click <button>Export</button> to save the localizations in a `.csv` file in your working directory (if you're using the structure of the git repo, use `./processing`). For this example, I will use the file name `localization_demo_U2OS_H2B_JF549_localizations.csv`. Make sure to check \"Save measurement protocol\" in the export dialog, which writes a second file containing all the ThunderSTORM settings we used for this localization process; this is essential for reproducibility.\n",
    "\n",
    "![Exporting localizations from ThunderSTORM. Make sure to check \"Save measurement protocol\"!](graphics/export.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eec1c1-c96a-40fc-9fd5-1cc6b842d6bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Linking localizations into trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d912d4-37b3-4da9-a73a-de0594514b33",
   "metadata": {},
   "source": [
    "We now have a file with individual localizations from all frames of our movie.\n",
    "\n",
    "(*If for some reason you did not complete the previous section, use the provided file* `backup_intermediate_files/localization_demo_U2OS_H2B_JF549_localizations.csv`)\n",
    "\n",
    "The problem with that file is that it does not tell us which localization in frame $n+1$ belongs to the same particle that we see somewhere in frame $n$; put another way, we have not yet *identified particles across different frames*. This is a non-trivial problem, and it is easy to imagine scenarios where it is impossible to solve: if our tracked particles moved fast enough to cover significant distance over the time between two frames, we might not be able to tell which spot moves where. Fortunately, chromatin is generally quite slow and the labelling density in the movie is low, such that this identification task should be feasible on our data (check by looking at the movie by eye: it is generally quite clear how to connect the dots).\n",
    "\n",
    "This section of the workshop walks you through one possible approach to linking together trajectories using the `trackpy` library. Note that instead of the GUI-based ThunderSTORM, we now move to coding ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365e7216-3b98-4ec7-8c9c-96f918182397",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395727e-d979-452c-ac3b-c4df0f3a4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `workingdir` should be the directory to work in\n",
    "# `loc_file`   should point to the ThunderSTORM results\n",
    "# The rest of this code sets up a few things that will come in handy later and can remain unchanged\n",
    "workingdir  = Path('./processing')\n",
    "loc_file    = workingdir / 'localization_demo_U2OS_H2B_JF549_localizations.csv'\n",
    "\n",
    "# Where to store plot output\n",
    "plot_folder = workingdir / 'plots'\n",
    "plot_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Where to store the final data set\n",
    "data_file = loc_file.with_suffix('.trajectories.h5')\n",
    "\n",
    "# Keep track of units\n",
    "units = {\n",
    "    'px_nm' : 128.7,\n",
    "    'px_um' : 0.1287,\n",
    "    'dt_ms' : 125,\n",
    "    'dt_s'  : 0.125,\n",
    "}\n",
    "\n",
    "# Set up a primitive logging mechanism\n",
    "# (better: https://docs.python.org/3/howto/logging.html)\n",
    "linklog_file = loc_file.with_suffix('.linklog.txt')\n",
    "with open(linklog_file, 'wt') as f:\n",
    "    f.write(f\"Linker logfile for file {str(loc_file.name)}\\n\")\n",
    "\n",
    "# Drop-in replacement for print(), to simultaneously write to log\n",
    "def log(line=\"\", file=linklog_file):\n",
    "    print(line)\n",
    "    with open(str(file), 'at') as f:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba045d1-e123-4837-949a-7650caea01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the ThunderSTORM localizations into a pandas DataFrame\n",
    "loc_df = pd.read_csv(loc_file, sep=',')\n",
    "loc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f71c4-70d8-4cc9-99cd-be851c5868b6",
   "metadata": {},
   "source": [
    "## A few sanity checks\n",
    "It is always a good idea to confirm that your data conforms to some basic expectations. In this example, we generate two simple plots:\n",
    "+ we check **which frame gives us how many localizations**; this is a plot we could also have done in ThunderSTORM. Its purpose is simply to get a feel for how many trajectories of what length we should expect. Due to photobleaching we will of course get many more localizations early in the movie.\n",
    "+ we check for **subpixel localization bias**. ThunderSTORM localizes the fluorophore location with a precision that can be an order of magnitude beyond the pixel size. This is possible because the PSF spans more than one pixel, so we can combine multiple intensities to triangulate the fluorophore more precisely. If this approach works correctly, we expect the measured position of the fluorophore to be independent of its real position relative to the pixel grid. As a quick check, we plot the density of the \"subpixel part\" of all localizations; we expect to see a homogeneous pattern with some shot noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07479904-afd0-4eab-b259-afd896717c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of localizations per frame\n",
    "plt.hist(loc_df['frame'], bins=np.arange(loc_df['frame'].max()+1)-0.5, density=False)\n",
    "\n",
    "plt.xlabel('frame')\n",
    "plt.ylabel('#localizations')\n",
    "plt.title('Localizations per frame')\n",
    "\n",
    "plt.savefig(plot_folder/'loc_per_frame.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f717f-a553-493b-ab4f-f281c26037be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subpixel bias\n",
    "x = loc_df['x [nm]']/units['px_nm'] % 1 - 0.5\n",
    "y = loc_df['y [nm]']/units['px_nm'] % 1 - 0.5\n",
    "\n",
    "bins = (np.linspace(-0.5, 0.5, 15), np.linspace(-0.5, 0.5, 15))\n",
    "h, _, _ = np.histogram2d(x, y, bins=bins, density=True)\n",
    "\n",
    "plt.pcolormesh(bins[0], bins[1], h.T,\n",
    "               cmap='gray',\n",
    "               vmin=0,\n",
    "              )\n",
    "plt.colorbar()\n",
    "plt.axis('square')\n",
    "plt.title('Subpixel localization density')\n",
    "\n",
    "plt.savefig(plot_folder/'subpixel.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f56ca0-60ef-4183-8352-4467d8a25787",
   "metadata": {},
   "source": [
    "## Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e18ec-a743-42f7-8cd6-6578bf4d7d0a",
   "metadata": {},
   "source": [
    "Having checked that our data looks reasonable, let's start linking it together into trajectories. The heavy lifting here is done by the `trackpy` library, but the basics are simple (see cartoon): for each localization in frame $n$ we draw a circle around it with a fixed radius. If there is one localization within this circle in frame $n+1$, we link the two together; if there are multiple candidates, we pick the closest one.\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "<img src=\"graphics/linking_sketch_small.png\" alt=\"Sketch: nearest neighbor linking\"/>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "If there is no point in the next frame, the trajectory ends in frame $n$; which might lead to a lot of trajectories being cut off prematurely. So we relax the condition a little bit, allowing for a few missing frames before a trajectories continues. These missing frames can come about for two reasons:\n",
    "+ fluorophores blinking: some fluorophores can temporarily switch to a non-fluorescent state, but reappear a little while later\n",
    "+ missed during localization step: remember that in the localization step we applied quite strong filter criteria; so we might well have filtered out some real spots that would appear as missing frames now.\n",
    "\n",
    "So, `trackpy` needs two parameters from us: a search radius, and a maximum \"memory\" span, i.e. for how long fluorophores are allowed to vanish between reappearances. Following the same idea as for the localization filtering above, we will apply rather restrictive criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a95290-83dc-47de-b4ef-49bb8052faaa",
   "metadata": {},
   "source": [
    "### Fixing a search range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fde8f-a384-4916-8eb7-5d8346cffa4e",
   "metadata": {},
   "source": [
    "How far should we allow a fluorophore to move between frames? Well, depends on how fast it moves; *which is one of the questions we aim to answer with our data!* We have a bit of a chicken-and-egg problem here: setting a reasonable search range depends on the dynamics of the molecule under study. In turn, the dynamics we will *observe* in our data, depend on this search range (since by construction steps in the trajectory cannot be larger than this cutoff). We should thus make sure that a) we can justify the choice of search range and b) it does not have a strong impact on the resulting trajectories. Fortunately, we can achieve both.\n",
    "\n",
    "To find a good search range, we resort to an exhaustive evaluation of the linking problem over one frame. This means: for each localization in each frame, calculate the distances to all localizations in the next frame and find the smallest one. We expect the distribution of these \"closest distances\" to be bimodal:\n",
    "+ either the same particle exists in the next frame and has not moved much; or\n",
    "+ the particle does not exist in the next frame, in which case the \"closest distance\" will be to some unrelated localization far away.\n",
    "\n",
    "The code cell below generates this distribution for our localization data; we can clearly identify the two modes and a cutoff between them, which will be our linking distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a802c4de-bbc6-4ef0-9582-dd7dd1ba1e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortest distances between frames\n",
    "Nframes = int(loc_df['frame'].max())\n",
    "dists = []\n",
    "for t in tqdm(range(1, Nframes)):\n",
    "    df0 = loc_df.loc[loc_df['frame'] == t,   ['x [nm]', 'y [nm]']]\n",
    "    df1 = loc_df.loc[loc_df['frame'] == t+1, ['x [nm]', 'y [nm]']]\n",
    "\n",
    "    if len(df0) > 0 and len(df1) > 0:\n",
    "        all_dx = df0.to_numpy()[:, None, :] - df1.to_numpy()[None, :, :]\n",
    "        shortest = np.min(np.linalg.norm(all_dx, axis=-1), axis=-1)\n",
    "        dists.append(shortest)\n",
    "    \n",
    "dists = np.concatenate(dists)\n",
    "\n",
    "plt.figure(figsize=[7, 3])\n",
    "\n",
    "plt.hist(dists, bins=units['px_nm']*np.logspace(-2.5, 2, 200), density=False)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('frame to frame nearest neighbor distance [nm]')\n",
    "plt.ylabel('count')\n",
    "plt.title('Closest distance across adjacent frames')\n",
    "\n",
    "plt.savefig(plot_folder/'frameframe_distances.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a652c-bbe3-40cd-ba7d-5928fbcdf9ec",
   "metadata": {},
   "source": [
    "Cool, this looks quite clear cut! Again, to be on the safe side, we might want to choose a somewhat restrictive setting, e.g. 200 nm instead of the 300 nm that the plot indicates. We expect not much of a difference (which we confirm below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ccceb-38a1-4984-8760-6e203b4d83e2",
   "metadata": {},
   "source": [
    "### Excercise 1: run the linker!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd0f2a9-1bbb-4f18-bf77-2f194b369a46",
   "metadata": {},
   "source": [
    "We are now set up to link trajectories! The call to the `trackpy.link()` routine works as shown below. It returns a new data frame with the added column `particle` identifying a trajectory: all localizations with the same `particle` number belong to the same trajectory.\n",
    "\n",
    "Note that we have not really discussed the value of the `memory` variable yet; what do you think would be a reasonable setting? How would you assess this?\n",
    "\n",
    "Execute the code below; vary the `memory` setting and assess the impact it has.*\n",
    "\n",
    "<font size=\"1\">*: purposefully vague statement; get creative!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb31f2f-4acf-4fad-a9a6-42253ac0b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linked = trackpy.link(loc_df,\n",
    "                         pos_columns  = ['y [nm]', 'x [nm]'],\n",
    "                         t_column     = 'frame',\n",
    "                         search_range = 300,     # search range in nm\n",
    "                         memory       = 0,       # maximum gap length, in frames\n",
    "                        )\n",
    "df_linked.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf98bf6-fd11-4cf2-9ac3-598556652d9a",
   "metadata": {},
   "source": [
    "### Running the linker with a few different settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225572f9-692e-496a-ab87-0e8cc8ad2b4e",
   "metadata": {},
   "source": [
    "The code below automates the \"just look at a few different settings\" approach. The metric we use to asses the impact of the linker settings is the trajectory survival curve, i.e. how many trajectories of what length we get. Run the two code cells below and check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b3061-3b16-4a19-b50b-d80516b282e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the values you want to test in the lists `search_range` and `memory`\n",
    "# The code will run through all combinations and output a trajectory survival curve for each\n",
    "search_range = [200, 300]\n",
    "memory = [0, 1, 2, 3]\n",
    "\n",
    "linking_settings = {f\"search_range = {sr} nm, memory = {mem} frames\" : dict(search_range = sr, memory = mem)\n",
    "                    for sr, mem in itertools.product(search_range, memory)\n",
    "                   }\n",
    "results = {}\n",
    "for label in linking_settings:\n",
    "    df_linked = trackpy.link(loc_df,\n",
    "                             pos_columns = ['y [nm]', 'x [nm]'],\n",
    "                             t_column = 'frame',\n",
    "                             **linking_settings[label],\n",
    "                             )\n",
    "    results[label] = df_linked\n",
    "\n",
    "# A red box talking about \"IOPub message rate exceeded\" might appear (and potentially disappear) below; it can be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577b079-a3d6-4f43-ae35-ca8bd60d6eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10, 4])\n",
    "fig.subplots_adjust(right=0.6)\n",
    "    \n",
    "for label in results:\n",
    "    _, cnt = np.unique(results[label]['particle'], return_counts=True)\n",
    "    plt.plot(np.sort(cnt), len(cnt)-np.arange(len(cnt)),\n",
    "             label=label,\n",
    "            )\n",
    "\n",
    "plt.legend(loc=(1.02, 0.1))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('#localizations N')\n",
    "plt.ylabel('#trajectories with more than N localizations')\n",
    "plt.title('Trajectory survival function')\n",
    "\n",
    "plt.savefig(plot_folder/'traj_survival.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c8597c-3ece-4459-b3c4-0a7ef00e69d9",
   "metadata": {},
   "source": [
    "### Identifying a good linker setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499bbb3-349c-4671-81f1-52b6a162bac2",
   "metadata": {},
   "source": [
    "From the survival curves above, we see that there is no appreciable difference between the search ranges of 200 or 300 nm. Being conservative, let's choose a 200 nm cutoff. The `memory` setting has a larger impact; but we seem to be able to capture most of the effect by allowing gaps of just 1 or 2 frames. Let's settle on `memory = 2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48dc0d2-9bc0-4949-ab30-8108a3a6a70b",
   "metadata": {},
   "source": [
    "## Assembling trajectories for further consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b6f319-c301-460d-8a7a-7b1fbb8dad7a",
   "metadata": {},
   "source": [
    "The data frame returned by the `trackpy` linker is a bit cumbersome to use for further analysis; so we reformat the data in an object oriented format. We use `noctiluca`'s `TaggedSet` structure, which facilitates iterating and slicing data sets like this one.\n",
    "\n",
    "At the same time, we will omit any trajectory shorter than 3 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8139739d-1f53-435b-8b1c-a4b443776d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `use_linking` to one of the options explored above\n",
    "# Set `minlen` to kick out very short trajectories\n",
    "use_linking = 'search_range = 200 nm, memory = 2 frames'\n",
    "minlen = 3\n",
    "\n",
    "# This conversion is a bit opaque\n",
    "# We are converting from the data frame you saw before to an object oriented format,\n",
    "# where each Trajectory is its own object, carrying its own meta data. We will\n",
    "# explore this structure below.\n",
    "df_linked = results[use_linking]\n",
    "csv_stream = io.StringIO(df_linked[['particle', 'frame', 'x [nm]', 'y [nm]', 'frame',\n",
    "                                    'intensity [photon]', 'sigma [nm]', 'uncertainty [nm]']].to_csv())\n",
    "data = nl.io.load.csv(csv_stream,\n",
    "                      [None, 'id', 't', 'x', 'y', # first column from pandas will be index\n",
    "                       'real frame',\n",
    "                       'intensity [photon]', 'sigma [nm]', 'uncertainty [nm]',\n",
    "                      ],\n",
    "                      delimiter=',', # pandas' default\n",
    "                      skip_header=1, # pandas prints a header line\n",
    "                     )\n",
    "data.addTags('real data')\n",
    "del df_linked\n",
    "\n",
    "# Convert distance units to μm\n",
    "data.apply(lambda traj : traj.rescale(1e-3, keepmeta=traj.meta.keys()), inplace=True)\n",
    "\n",
    "# Eliminate super short \"trajectories\" (i.e. stray localizations)\n",
    "data.makeSelection(lambda traj, _: traj.F < minlen)\n",
    "data.deleteSelection()\n",
    "\n",
    "# Fix up 'real frame' numbers\n",
    "for traj in data:\n",
    "    traj.meta['real frame'] = np.arange(np.nanmin(traj.meta['real frame']),\n",
    "                                        np.nanmax(traj.meta['real frame'])+1,\n",
    "                                       ).astype(int)\n",
    "    traj.meta['real frame'] -= 1 # 'real frame' comes from the trackpy linker, which is 1-based\n",
    "    assert len(traj) == len(traj.meta['real frame'])\n",
    "    assert traj.meta['real frame'].min() >= 0\n",
    "\n",
    "# Log used linking settings\n",
    "log()\n",
    "log( \"Linking settings\")\n",
    "log( \"----------------\")\n",
    "log(f\"use_linking = '{use_linking}'\")\n",
    "log(f\"minlen      = {minlen}\")\n",
    "log()\n",
    "log(f\"{len(data)} trajectories assembled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec957599-ff1f-4145-98d7-6391adb2a0c4",
   "metadata": {},
   "source": [
    "In the code above, we reformatted the trajectory data extracted from our example movie in an object-oriented fashion: we assembled a `TaggedSet` of `Trajectory` objects. **Why?**\n",
    "\n",
    "(*You can skip this discussion and go straight to Excercise 2; refer to the bullet lists for basic usage of the data structures. You can also check [the full documentation](https://noctiluca.readthedocs.io/en/latest/)*)\n",
    "\n",
    "Simply put, our data now has additional structure. While before the linking step we just had a long list of localizations (for which the tabular `pandas` data frame was a great format), after linking we now have a set of trajectories, each of which contains many localizations; it is worth structuring our data similar to our thinking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e837fb-033f-4ebf-bf97-fb2e4f10e68d",
   "metadata": {},
   "source": [
    "A `Trajectory` object (let's call it `traj`) is mostly a thin wrapper of the `numpy.ndarray` storing the actual data. Useful attributes and operations include\n",
    "+ `traj.data`: the underlying `numpy` array; should usually not be necessary to access directly.\n",
    "  + Note that a `Trajectory` contains localizations for a contiguous interval of frames, instead of storing a list of localizations and which frame they come from. This means that gaps are now explicit, indicated by `np.nan` values in `traj.data`.\n",
    "+ `traj[:]`: trajectories can be indexed and sliced by frame number; this is preferred to accessing `data` directly\n",
    "+ `traj.T` or `len(traj)`: total length in `T`ime (frames) of the trajectory, including gaps\n",
    "+ `traj.F`: total number of *valid* `F`rames in the trajectory, i.e. excluding gaps\n",
    "+ `traj.meta`: a dict where arbitrary meta-data can be stored. In our example data set, this contains e.g. the `uncertainty [nm]` reported by ThunderSTORM for each localization. This is also handy to store some precalculated analyses, e.g. MSD data (which we will come back to below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751aaf5e-e9a1-48fb-b0d7-16c5e54250cf",
   "metadata": {},
   "source": [
    "A `TaggedSet` is designed to act as a container for many trajectories (or other objects, for that matter). **Why not just use python's `list` or `set`?** Again the reasoning is that our data usually has additional structure that we wish to utilize.\n",
    "\n",
    "When analyzing real data sets, we usually have multiple experimental conditions: drug treatments, controls, acquisition settings, etc. For analysis, we might want to stratify by some of these parameters, but pool others; or maybe we want to run some analysis only on very \"clean\" trajectories; or, conversely, maybe there is some post-processing that we need to do on all trajectories the same, regardless of condition. So, pictorially speaking, we would like to think of our data set as a big, unsorted pile of single trajectories; whenever we want to run some analysis, we go through the pile and pick out all trajectories that belong to some experimental condition; were acquired over two specific experiment days; or fulfill some other obscure criterion. A code representing of this thinking is afforded by the `TaggedSet` data structure and its `makeSelection()` mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72418554-0c28-40fd-afca-55188fb4e033",
   "metadata": {},
   "source": [
    "Let's analyze one line from the code above. The variable `data` is a `TaggedSet` containing all our linked trajectories.\n",
    "```python\n",
    "data.makeSelection(lambda traj, _: traj.F < minlen)\n",
    "```\n",
    "This line selects all the trajectories in the data set that have fewer than `minlen`(=3) valid localizations. `data` will now behave as if it contained only those trajectories; you could e.g. check how many there are (`len(data)`) or iterate through them one by one (`for traj in data: ...`). The argument to `makeSelection()` can be one of a few different things:\n",
    "+ **no argument** (i.e. `data.makeSelection()`) resets the selection to the full data set\n",
    "+ **a function** evaluating a selection criterion. This is what we do above: in python we can define simple unnamed functions with the `lambda` keyword; so `lambda traj, _: traj.F < minlen` is a function taking two arguments (we will ignore the second one for the time being), returning `True` if the trajectory fulfills our cutoff condition. We could have achieved the same result with the more verbose\n",
    "```python\n",
    "    def is_short(traj, _):\n",
    "        return traj.F < minlen\n",
    "    data.makeSelection(is_short)\n",
    "```\n",
    "+ **a tag**; the \"Tagged\" part of `TaggedSet`. Frequently, we want to select trajectories not based on their data, but on some label we attach to them, e.g. the experimental condition. In the code above, you might be able to find the line where we attached the tag `'real data'` to all our trajectories. So when we add some synthetic data to the mix, you will be able to pick out the real data again.*\n",
    "+ **some special keyword arguments**: `nrand=...` or `prand=...` let you select a fixed number or given fraction of the data set at random.\n",
    "\n",
    "<font size=\"1\">*: You might now be able to guess the second argument to the selection function: all the tags associated with the trajectory. So you can select trajectories based on some combination of tags and data, or apply some complicated criterion on the tags.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb63462-6ddf-4473-bc87-f89409f4f16a",
   "metadata": {},
   "source": [
    "Now that we have an overview over the central `makeSelection()` mechanism, how do you access the trajectories you selected?\n",
    "+ `for traj in data: ...` iterates through all the trajectories in the current selection; most frequent use case\n",
    "+ `data[0]` you can just index the current selection with an integer; usually not preferred\n",
    "+ `len(data)` gives the count of items in the current selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99118df-4122-4c22-9490-de585f5d71a9",
   "metadata": {},
   "source": [
    "For more details refer to the [documentation](https://noctiluca.readthedocs.io/en/latest/examples/02_TaggedSet.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b088c5-d1ec-4325-8d55-8a80aaa4c98c",
   "metadata": {},
   "source": [
    "### Excercise 2: basics of `TaggedSet`s and `Trajectory`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ca98eb-6dbc-4e24-b195-eb46b71c0918",
   "metadata": {},
   "source": [
    "Using the bullet lists in the above discussion as reference, find answers to the following questions\n",
    "+ what is the average fraction of valid frames per trajectory? (i.e. how contiguous is our data?)\n",
    "+ do short trajectories tend to have more or fewer missing frames?\n",
    "+ replot the trajectory survival curve we saw above. Show the survival as function of total number of frames, and number of valid frames.\n",
    "+ plot a histogram of the `uncertainty [nm]` reported by ThunderSTORM (this is stored as part of `traj.meta` in the individual trajectories). If you have time, overlay a histogram of the mean uncertainty of whole trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f90cff-8447-4256-a514-612a0f026b33",
   "metadata": {},
   "source": [
    "The following `numpy` functions might be useful:\n",
    "```python\n",
    "arr = np.sort(arr)                      # sort an array/list `arr`\n",
    "arr = np.concatenate([arr0, arr1, ...]) # string multiple arrays together\n",
    "arr = arr[~np.isnan(arr)]               # remove invalid values from an array\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb21ff9-c501-4edc-bc2b-a0fdff03bd93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dbfab8e-0bf5-4ae5-8bd3-d396168d02e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Solution to Excercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef093b0-e225-440c-b205-f36b8ce670b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average fraction of valid frames in data set\n",
    "def f_valid(data):\n",
    "    return np.mean([traj.F/len(traj) for traj in data])\n",
    "data.makeSelection()\n",
    "print(f\"Fraction of valid frames in whole data set:     {f_valid(data):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d88e83-f2d1-4f67-9e57-bf95611ac4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify by long and short trajectories\n",
    "cutoff = 10 # \"long\": longer than this; \"short\" shorter than this\n",
    "\n",
    "data.makeSelection(lambda traj, _: len(traj) <  cutoff)\n",
    "print(f\"Fraction of valid frames in short trajectories: {f_valid(data):.1%}\")\n",
    "\n",
    "data.makeSelection(lambda traj, _: len(traj) >= cutoff)\n",
    "print(f\"Fraction of valid frames in long  trajectories: {f_valid(data):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fae7b-a7d1-4eb1-be0f-41429db7519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival curves\n",
    "data.makeSelection()\n",
    "Ts = np.flip(np.sort([traj.T for traj in data]))\n",
    "Fs = np.flip(np.sort([traj.F for traj in data]))\n",
    "y = np.arange(len(data))\n",
    "\n",
    "plt.plot(Ts, y, label='total frames')\n",
    "plt.plot(Fs, y, label='valid frames')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('trajectory length / valid frames')\n",
    "plt.ylabel('#trajectories longer than')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c69b95-bc0a-4682-8060-3a604df71612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of ThunderSTORM uncertainty\n",
    "data.makeSelection()\n",
    "uncertainties = np.concatenate([traj.meta['uncertainty [nm]'] for traj in data])\n",
    "uncertainties = uncertainties[~np.isnan(uncertainties)]\n",
    "\n",
    "traj_uncertainties = np.array([np.nanmean(traj.meta['uncertainty [nm]']) for traj in data])\n",
    "\n",
    "plt.hist(uncertainties, bins='auto', density=True, label='localizations')\n",
    "plt.hist(traj_uncertainties, bins='auto', density=True, alpha=0.5, label='trajectory means')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('uncertainty [nm]')\n",
    "plt.ylabel('density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb37d692-5a18-4def-8633-bc5268f02261",
   "metadata": {},
   "source": [
    "### Excercise 3: plotting trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b9057f-537d-4a5d-b24b-a1b2b7bb5f2d",
   "metadata": {},
   "source": [
    "Let's take an actual look at our data! Display all trajectories together in a plot of (coordinate) vs. (time). Use `traj.meta['real frame']` as the time coordinate and pick either of the two coordinates to display (or generate plots for both).\n",
    "\n",
    "How well did the linking work?\n",
    "\n",
    "Hint: `traj[:][:, 0]` gives the 0-coordinate (one might call it $x$) of a trajectory `traj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc92f8d-3eb4-48a4-9e23-177cff54f52d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d488beb-5bb0-475d-bc35-db0585ef5ee4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Solution to Excercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f7abd-f251-47ce-9311-0f192e263dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.makeSelection()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=[15, 4])\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    for traj in data:\n",
    "        ax.plot(traj.meta['real frame'], traj[:][:, i])\n",
    "\n",
    "    ax.set_title(f'coordinate {i} [μm]')\n",
    "    ax.set_xlabel('time [frames]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87b828-e4e2-4661-92f6-3b13e9df807a",
   "metadata": {},
   "source": [
    "Overall, the linking performance seems quite good! (there are no obvious mislinkings, and trajectories do have a decent length. However, there are also a few clear examples where the linker missed a connection and we end up with multiple smaller snippets of an actually longer trajectory. This is generally good; remember our philosophy of \"better to lose some good data than include garbage\". Nevertheless, we might want to stitch back together the obvious ones in a post-processing step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb3bf1-f26c-4ed5-b401-de25aca8df5b",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54f302-510c-4912-8bd0-c9db23d58812",
   "metadata": {},
   "source": [
    "Depending on data quality and experimental setup, different quality control steps (filtering, post-processing, pruning, ...) might be applied to get a \"clean\" data set. In this example, we will try to stitch together trajectories that reappear in the same spot after a few gap frames.\n",
    "\n",
    "After the gap stitching step, we then again filter out short trajectories, where \"short\" now means anything that's too short to really be meaningful. I often use a cutoff of at least 10 localizations per trajectory.\n",
    "\n",
    "We will not go through this code in detail. You can use your code (or the provided solution) from Excercise 3 to check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf8d86-f875-4eec-98e9-ba579d2025d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_gap = 10 # frames\n",
    "max_step = linking_settings[use_linking]['search_range'] * 1e-3 # nm --> μm\n",
    "\n",
    "# Make sure that trajectories have valid first and last frame\n",
    "data.makeSelection()\n",
    "assert ~np.any(np.isnan([traj[0] for traj in data]))\n",
    "assert ~np.any(np.isnan([traj[-1] for traj in data]))\n",
    "\n",
    "# Figure out which trajectories to link together\n",
    "start_pos = np.array([traj[0] for traj in data])\n",
    "end_pos = np.array([traj[-1] for traj in data])\n",
    "start_frame = np.array([traj.meta['real frame'][0] for traj in data])\n",
    "end_frame = np.array([traj.meta['real frame'][-1] for traj in data])\n",
    "\n",
    "for i, traj in enumerate(data):\n",
    "    dist_past   = np.linalg.norm(start_pos[i] -   end_pos, axis=-1)\n",
    "    dist_future = np.linalg.norm(  end_pos[i] - start_pos, axis=-1)\n",
    "    ind_link_past = (end_frame < start_frame[i]) \\\n",
    "                    & (end_frame + max_gap + 1 >= start_frame[i]) \\\n",
    "                    & (dist_past < max_step)\n",
    "    ind_link_future = (start_frame > end_frame[i]) \\\n",
    "                    & (start_frame <= end_frame[i] + max_gap + 1) \\\n",
    "                    & (dist_future < max_step)\n",
    "    \n",
    "    traj.meta['to relink'] = set(np.nonzero(ind_link_past)[0]) | set(np.nonzero(ind_link_future)[0])\n",
    "    \n",
    "# Sanity check (symmetry) and setup for execution\n",
    "for i, traj in enumerate(data):\n",
    "    traj.meta['is relinked'] = False\n",
    "    for j in traj.meta['to relink']:\n",
    "        assert i in data[j].meta['to relink']\n",
    "        \n",
    "# Execute!\n",
    "new_data = nl.TaggedSet()\n",
    "for i, (curtraj, tags) in enumerate(data(giveTags=True)):\n",
    "    if not curtraj.meta['is relinked']:\n",
    "        # Assemble full set of trajectories to link together\n",
    "        trajs = [curtraj]\n",
    "        in_list = {i}\n",
    "        to_add = curtraj.meta['to relink'] - in_list # just to be safe\n",
    "        while to_add:\n",
    "            for j in list(to_add): # copy to avoid changing size during loop\n",
    "                in_list.add(j)\n",
    "                trajs.append(data[j])\n",
    "                to_add |= data[j].meta['to relink']\n",
    "            to_add -= in_list\n",
    "            \n",
    "        # Sanity check\n",
    "        assert not any([traj.meta['is relinked'] for traj in trajs])\n",
    "        \n",
    "        # Assemble\n",
    "        all_rf = np.concatenate([traj.meta['real frame'] for traj in trajs])\n",
    "        new_traj = nl.Trajectory(np.concatenate([traj[:] for traj in trajs], axis=0),\n",
    "                                 t=all_rf,\n",
    "                                )\n",
    "        \n",
    "        # Transfer meta data\n",
    "        min_rf = np.min(all_rf)\n",
    "        new_traj.meta['real frame'] = np.arange(min_rf, np.max(all_rf)+1)\n",
    "        assert len(new_traj) == len(new_traj.meta['real frame'])\n",
    "        \n",
    "        for key in ['uncertainty [nm]',\n",
    "                    'intensity [photon]',\n",
    "                    'sigma [nm]',\n",
    "                   ]:\n",
    "            new_trace = np.empty(len(new_traj), dtype=float)\n",
    "            new_trace[:] = np.nan\n",
    "            new_trace[all_rf-min_rf] = np.concatenate([traj.meta[key] for traj in trajs])\n",
    "            new_traj.meta[key] = new_trace\n",
    "        \n",
    "        # Add to data set\n",
    "        new_data.add(new_traj, tags)\n",
    "        for traj in trajs:\n",
    "            traj.meta['is relinked'] = True\n",
    "            \n",
    "data = new_data\n",
    "del new_data\n",
    "log(f\"{len(data)} trajectories left after relinking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e23318-4645-407f-bd50-a0894d2a4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, kick out short trajectories\n",
    "min_frames_valid = 10\n",
    "data.makeSelection(lambda traj, _: traj.F < min_frames_valid)\n",
    "data.deleteSelection()\n",
    "log(f\"{len(data)} trajectories with >= {min_frames_valid} valid detections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a342ee-4c1d-481b-9cdc-beac66fba512",
   "metadata": {},
   "source": [
    "## Plot MSDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229efa80-24d9-4fa4-872a-2ff67b22e30c",
   "metadata": {},
   "source": [
    "We run one quick little bit of analysis before concluding the data assembly process: let's calculate MSDs for all trajectories and take a look. This generally helps getting a first understanding for what's happening in our data; we will talk more about this in the third section of the workshop.\n",
    "\n",
    "A technical reason to run the MSD calculation at this point is that `Trajectory`s memoize their MSDs; this makes it faster to calculate ensemble MSDs down the line, e.g. for subsets of data. For this reason, I often run something like\n",
    "```python\n",
    "_ = nl.analysis.MSD(data)\n",
    "```\n",
    "before saving a data set, just to make sure I get the pre-calculated MSDs when I start analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e953625-4db5-4abb-ac95-bdf464450310",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.makeSelection()\n",
    "dt = units['dt_s']\n",
    "\n",
    "msd = nl.analysis.MSD(data)\n",
    "plt.plot(dt*np.arange(1, len(msd)), msd[1:],\n",
    "         color='k', linewidth=2,\n",
    "         label='ensemble mean',\n",
    "         zorder=10,\n",
    "        )\n",
    "for traj in data:\n",
    "    msd = nl.analysis.MSD(traj)\n",
    "    plt.plot(dt*np.arange(1, len(msd)), msd[1:],\n",
    "             alpha=0.5,\n",
    "            )\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('lag time [sec]')\n",
    "plt.ylabel('MSD [μm²]')\n",
    "plt.ylim([1e-4, None])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title(f\"MSDs for {loc_file.name}\")\n",
    "\n",
    "plt.savefig(plot_folder/'MSDs.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781fffc0-53af-4c63-9aae-e42410e27fba",
   "metadata": {},
   "source": [
    "## Save the linked trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3843a76-1530-4c2a-beb2-4d3656fd353b",
   "metadata": {},
   "source": [
    "We use the HDF5 file format, which is a binary storage format for generic structured data. One benefit of this is that we are essentially just writing a `dict`; so we can add additional entries, such as a short (better long!) description of the data. This is a good place to keep important comments on what the data is, where it comes from, eventual additional information, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016e0c3-0bd2-4540-8257-f8c673789948",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = \"\"\"\n",
    "Trajectories tracked during the image processing workshop\n",
    "\n",
    "Units in the trajectories are μm.\n",
    "Time between frames is 125 ms.\n",
    "Acquired with continuous exposure (--> motion blur!)\n",
    "\"\"\"[1:-1]\n",
    "\n",
    "data.makeSelection()\n",
    "nl.io.write.hdf5({'data' : data, 'description' : desc}, data_file)\n",
    "print(\"Saved data to     \", str(data_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db6dc5-86d1-44d3-9bbb-ac9bfdb96363",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Analyzing trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897ad298-e599-42a8-8bb0-423f9608e2a9",
   "metadata": {},
   "source": [
    "Let's investigate the trajectories from our movie! We start by reading the file that we just saved back into memory.\n",
    "\n",
    "(*if for some reason you did not complete the previous section, use the provided file* `backup_intermediate_files/localization_demo_U2OS_H2B_JF549_localizations.trajectories.h5`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b521f-f347-4db7-953a-c03b99dc0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = Path('./processing/localization_demo_U2OS_H2B_JF549_localizations.trajectories.h5')\n",
    "print(nl.io.load.hdf5(data_file, 'description'))\n",
    "data = nl.io.load.hdf5(data_file, 'data')\n",
    "dt = 0.125 # seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee4b54-2f96-469c-ae2a-72984a5dcc2f",
   "metadata": {},
   "source": [
    "## First steps\n",
    "It is usually a good idea to have an overview of what your data looks like. To that end, we will replot the survival curve and MSD we already saw in the section on linking; this is mostly for completeness here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1fb99-2472-4dca-bc2a-6581a7d6b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival curve\n",
    "lens = np.flip(np.sort([len(traj) for traj in data]))\n",
    "plt.plot(lens, np.arange(len(lens)))\n",
    "\n",
    "plt.title('Trajectory survival curve')\n",
    "plt.xlabel('length [frames]')\n",
    "plt.ylabel('#trajectories longer than X')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eebf7b-439e-48cd-a7b4-60c0945342c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSDs\n",
    "for traj in data:\n",
    "    msd = nl.analysis.MSD(traj)\n",
    "    plt.plot(dt*np.arange(1, len(msd)), msd[1:],\n",
    "             alpha=0.5,\n",
    "            )\n",
    "\n",
    "msd = nl.analysis.MSD(data)\n",
    "plt.plot(dt*np.arange(1, len(msd)), msd[1:],\n",
    "         color='k', linewidth=2, zorder=10,\n",
    "         label='ensemble mean',\n",
    "         )\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('lag time [frames]')\n",
    "plt.ylabel('MSD [μm²]')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim([1e-4, None])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96bebb-c0f9-4100-8a95-71065a86c342",
   "metadata": {},
   "source": [
    "Overall, this looks like a decent data set: we have a few trajectories with more than 100 frames, we do not immediately see any strange artefacts, and the single trajectory MSDs look relatively homogeneous (we cannot clearly distinguish multiple different classes). Remember that this data set comes from tracking a single nucleus; for a real experiment we would of course generate more data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f03db-5044-4601-8a6a-8c9bd7445e52",
   "metadata": {},
   "source": [
    "## MSD analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76975ada-fc84-42f0-a842-626ea8bf7a50",
   "metadata": {},
   "source": [
    "We have plotted this curve multiple times by now; let's understand what it is!\n",
    "\n",
    "MSD stands for \"Mean Squared Displacement\" and is calculated from trajectories $x(t)$ using the following formula:\n",
    "$$\n",
    "\\mathrm{MSD}(\\Delta t) = \\left\\langle \\left( x(t+\\Delta t) - x(t) \\right)^2 \\right\\rangle\\,,\n",
    "$$\n",
    "where $\\langle\\cdot\\rangle$ indicates an average. For this workshop, we will always average over the time $t$ and usually over multiple trajectories.*\n",
    "\n",
    "So the MSD indicates how far our particles typically move during a given window of time $\\Delta t$. The dependence on $\\Delta t$ is thus an interesting characteristic of the particle motion. A few examples (with illustration below):\n",
    "\n",
    "+ a particle moving in a **straight line**: $x(t) = vt$. Plugging into the formula above, one quickly finds $\\mathrm{MSD}(\\Delta t) = v^2\\Delta t^2$; so the MSD is *quadratic* in lag time $\\Delta t$. This is often called *ballistic motion*\n",
    "+ a **random walker**: consider a particle jumping around randomly with steps of size $s$; more precisely, we assume the displacement $x(t+1) - x(t)$ over one unit of time to be normally distributed with variance $s^2$. Because subsequent steps are uncorrelated, the displacement $x(t+n) - x(t)$ after $n$ steps will be normal with variance $ns^2$; from which we conclude that $\\mathrm{MSD}(\\Delta t) = s^2\\Delta t$. So the MSD is *linear* in lag time $\\Delta t$; this is referred to as *diffusive motion*.\n",
    "+ **white noise**: imagine a particle that just appears in a random (normally distributed with variance $\\sigma^2$) position somewhere around a fixed point, every time we record its location. Its \"trajectory\" would be described by $x(t) = \\sigma \\xi(t)$, where $\\xi(t)$ are uncorrelated standard normal variables at each time $t$. For the MSD, we then find\n",
    "$$\n",
    "\\mathrm{MSD}(\\Delta t) = \\left\\langle \\left( \\sigma\\xi(t+\\Delta t) - \\sigma\\xi(t) \\right)^2 \\right\\rangle = \\sigma^2 \\left\\langle \\xi^2(t+\\Delta t) - 2\\xi(t+\\Delta t)\\xi(t) + \\xi^2(t) \\right\\rangle = \\begin{cases}2\\sigma^2 & \\Delta t > 0 \\\\ 0 & \\Delta t = 0\\end{cases}\\,.\n",
    "$$\n",
    "So the MSD is *independent* of the lag time $\\Delta t > 0$. Note how this \"particle appearing randomly somewhere close to a given location\" might be a good representation for the *error* when localizing a real particle!\n",
    "+ **polymers**: imagine a locus on a polymer. Driven by Brownian motion, it \"wants\" to diffuse, but gets held back by the rest of the chain it would have to drag along. It will be more constrained than free diffusion, but at the same time not actually bound to a fixed location; we might expect some intermediate behavior between the above two examples of diffusion and white noise. Indeed, in the simplest toy model of a polymer (the \"Rouse model\"), one finds that $\\mathrm{MSD}(\\Delta t) \\propto \\Delta t^{0.5}$; a *square root* law. Different polymer models make different predictions for the precise exponent in this law, but they generally fall within the range of $(0, 1)$; this regime is called *sub-diffusion*.\n",
    "\n",
    "![Visualization of different MSD exponents](graphics/MSD_scalings.png)\n",
    "\n",
    "<font size=\"1\">\n",
    "*: The literature sometimes refers to this as \"TA-MSD\" (for \"time-averaged\" MSD), as opposed to keeping the time $t$ fixed (e.g. at the beginning of each trajectory). Since our trajectories do not begin at a definite time anyways, we always use TA-MSD here, dropping the \"TA-\" for convenience.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b6fea-3e2e-4e68-8bd8-63e64a7ac7f0",
   "metadata": {},
   "source": [
    "**Question 1**: Check the MSD plot for our data above. What type of motion do we observe? Does that make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa95fabb-bfa1-4610-9dd3-9b0b128a9fb0",
   "metadata": {},
   "source": [
    "## Error terms and the MSD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f45038-f5a4-4e39-9070-06f87e999f36",
   "metadata": {},
   "source": [
    "The reported localizations in our data do not give the exact location of the tracked fluorophore at a specific time. There are two sources of error that we have to consider:\n",
    "+ **localization error**: because we collect only a finite number of photons for each localization, the precision with which we can pinpoint the central location of the PSF is limited. As hinted above, this is usually modelled as additive Gaussian noise, i.e. we assume that for each localization, we take the true position and add a Gaussian random variable with variance $\\sigma$.\n",
    "+ **motion blur**: to collect photons for each frame, we have to set a finite *exposure time* $\\Delta t_\\text{expose}$ on the camera. For high-speed, low-intensity acquisitions, it is not uncommon to just expose for the whole duration between two frames, which is the case e.g. with our movie here. So the localizations we get from each frame in the movie are *averaged* over the exposure time.\n",
    "\n",
    "The effect of motion blur gets stronger the more \"constrained\" the particle motion is (i.e. the lower the exponent). Consider the two extremes: for ballistic motion, averaging over the exposure time changes nothing, since the particle moves in a straight line either way. For white noise, averaging over any finite exposure time amounts to averaging infinitely many Gaussian random variables, which just yields their mean; so in fact we lose *all* the signal!\n",
    "\n",
    "Fortunately, we can calculate the effect of motion blur on the observed MSD. The dominant effect is the subtraction of a constant, i.e.\n",
    "$$\n",
    "\\mathrm{MSD}_\\text{motion blurred}(\\Delta t) = \\mathrm{MSD}_\\text{real}(\\Delta t) - 2B\\,,\n",
    "$$\n",
    "with\n",
    "$$\n",
    "B = \\frac{\\mathrm{MSD}_\\text{real}(\\Delta t_\\text{expose})}{(\\alpha + 1)(\\alpha + 2)}\\,.\n",
    "$$\n",
    "To derive these formulas (not shown here), we assumed that $\\mathrm{MSD}_\\text{real}(\\Delta t) = \\Gamma\\Delta t^\\alpha$ is a powerlaw with some exponent $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5d9db6-b6d3-4e41-bc53-7d8ceb61c7da",
   "metadata": {},
   "source": [
    "**Question 2: motion blur**. Forgetting about localization error for the time being (i.e. assume $\\sigma = 0$), estimate the effect of motion blur (i.e. the constant $B$) from our data. You can assume that $\\alpha = 0.5$. How would you correct the MSD curve for this effect? Make a plot showing the raw and corrected curves.\n",
    "\n",
    "Hints:\n",
    "+ acquisition for this movie was continuous, i.e. $\\Delta t_\\text{expose} = 1\\text{ frame}$\n",
    "+ you can use the line  \n",
    "  ```python\n",
    "      msd = nl.analysis.MSD(data)\n",
    "  ```  \n",
    "  to calculate the ensemble MSD of our data set. Keep in mind that this will of course be $\\mathrm{MSD}_\\text{motion blurred}$!\n",
    "+ start by finding an expression for $\\mathrm{MSD}_\\text{real}(\\Delta t_\\text{exposed})$ in terms of $\\mathrm{MSD}_\\text{motion blurred}(\\Delta t_\\text{exposed})$. Once you have that, you can calculate $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf20e7-e761-4495-bd88-0c54d7b1acd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f02c8ae7-0936-4801-a701-99b71fa68195",
   "metadata": {},
   "source": [
    "**Question 3: localization error**. How does localization error affect the MSD? As hinted above, a decent model for localization error is to assume that we just add a little bit of white noise to our trajectories. Since the noise is uncorrelated with the real data, the MSDs just add (it is instructive to convince yourself of this by going through the calculation!). We found above that the MSD for white noise is $\\mathrm{MSD}(\\Delta t) = 2\\sigma^2$; since we add noise for both the $x$- and $y$- dimensions, we get another factor of 2, giving rise to\n",
    "$$\n",
    "\\mathrm{MSD}_\\text{with localization error} = \\mathrm{MSD}_\\text{ideal} + 4\\sigma^2\\,.\n",
    "$$\n",
    "\n",
    "In the section on linking we plotted a histogram of the localization uncertainties reported by ThunderSTORM. Refer to the plot and pick a reasonable consensus value (you can calculate a mean; or just pick something by eye). Correct the MSD curve from Question 2 with this value and add the result to your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ca71a-a1fd-4931-bddb-106da2ddc47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "638ac3e2-fd8b-415e-b8aa-53ff0153ea42",
   "metadata": {},
   "source": [
    "### Solution to Questions 2 & 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf7ce9-c9a2-4cc0-91a1-fea761626117",
   "metadata": {},
   "source": [
    "Evaluating the top equation at $\\Delta t_\\text{expose}$ and plugging in the expression for $B$ gives\n",
    "$$\n",
    "\\mathrm{MSD}_\\text{motion blurred}(\\Delta t_\\text{expose}) = \\left[ 1 - \\frac{2}{(\\alpha+1)(\\alpha+2)} \\right] \\mathrm{MSD}_\\text{real}(\\Delta t_\\text{expose})\\,,\n",
    "$$\n",
    "which we can rewrite as\n",
    "$$\n",
    "\\mathrm{MSD}_\\text{real}(\\Delta t_\\text{expose}) = \\frac{(\\alpha+1)(\\alpha+2)}{\\alpha^2 + 3\\alpha} \\mathrm{MSD}_\\text{motion blurred}(\\Delta t_\\text{expose})\\,.\n",
    "$$\n",
    "Plugging into the equation for $B$, we get\n",
    "$$\n",
    "B = \\frac{\\mathrm{MSD}_\\text{motion blurred}(\\Delta t_\\text{expose})}{\\alpha(\\alpha+3)}\\,.\n",
    "$$\n",
    "\n",
    "Now (keeping in mind that $\\Delta t_\\text{expose} = 1$ frame) we can evaluate this expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e4830-d626-41b1-adef-b31fc02b38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate motion blur\n",
    "msd = nl.analysis.MSD(data)\n",
    "a = 0.5\n",
    "\n",
    "B = msd[1]/(a*(a+3))\n",
    "print(f\" B  = {B:.3g} μm²\")\n",
    "\n",
    "# Localization error\n",
    "loc_err = 15               # nm (from histogram)\n",
    "sigma2 = (loc_err*1e-3)**2 # μm²\n",
    "print(f\"4σ² = {4*sigma2:.3g} μm²\")\n",
    "\n",
    "# Make a plot\n",
    "plt.plot(dt*np.arange(1, len(msd)), msd[1:],\n",
    "         label='raw',\n",
    "        )\n",
    "plt.plot(dt*np.arange(1, len(msd)), msd[1:]+2*B,\n",
    "         label='motion blur corrected',\n",
    "        )\n",
    "plt.plot(dt*np.arange(1, len(msd)), msd[1:]+2*B-4*sigma2,\n",
    "         label='motion blur and\\nlocalization error corrected',\n",
    "        )\n",
    "\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('lag time [sec]')\n",
    "plt.ylabel('MSD [μm²]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfbe3de-4776-4381-9bea-3153c116d15a",
   "metadata": {},
   "source": [
    "Clearly it is important to correctly deal with these two error terms! In our case motion blur is the dominant contribution; in general, either or both might be important.\n",
    "\n",
    "However: so far we took a pretty casual approach to these corrections. In the next section we will learn about a more principled treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fef0a8-b674-4c64-a285-ef6733204123",
   "metadata": {},
   "source": [
    "## Parameter inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bab969-3751-41ca-a31d-766cb6290454",
   "metadata": {},
   "source": [
    "How can we learn parameters (such as the anomalous exponent $\\alpha$) in a statistically rigorous way?\n",
    "\n",
    "The literature standard is to take the MSD curve we plotted above, plot a powerlaw (straight line in log-space) with some slope next to it, and report \"looks like this or that exponent\".\n",
    "\n",
    "Two points make this approach problematic:\n",
    "+ the error terms we explored in the previous section distort the MSD curve; the motion blur term actually depends on the parameters of the *true* process, creating a somewhat circular logic (remember that when we explored motion blur above, I just told you to set $\\alpha = 0.5$; of course you can't do that in the real world).\n",
    "+ strongly correlated errors in the MSD curve make simple curve fitting (e.g. least squares) unreliable. Check the MSD curve above: towards the end it does some random things, but it doesn't really \"look as noisy as one would expect if all of that was just random fluctuation\". This is exactly the effect of correlated errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046fd242-d2d0-40ec-b79b-ec499616d8e4",
   "metadata": {},
   "source": [
    "**Question 4: noise in MSD curves**. Randomly select half of the trajectories from our data set and plot the MSD curve of that ensemble. Repeat a few times and plot all the curves on the same plot. Note how the curves diverge quite a lot, even in places where they don't really \"look noisy\" yet.\n",
    "\n",
    "Hint: you can use `data.makeSelection(prand=0.5)` to randomly select half the trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac3550-46bc-48d0-8d2f-9cd6ed381c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec927a83-03d4-4fc8-8880-5cb3ca0c4b98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution to Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39f836-d8c9-4d68-a50f-a1c343a5cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    data.makeSelection(prand=0.5)\n",
    "    msd = nl.analysis.MSD(data)\n",
    "    plt.plot(dt*np.arange(1, len(msd)), msd[1:])\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('lag time [sec]')\n",
    "plt.ylabel('MSD [μm²]')\n",
    "plt.title('Noise in MSD curves\\nEach curve is ensemble MSD for randomly selected 50% of trajectories')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ffeb46-6032-4995-9632-8b4abe082cbf",
   "metadata": {},
   "source": [
    "### So, how do we fit this properly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee52c15-a34d-4205-95d9-fb53acfbff69",
   "metadata": {},
   "source": [
    "Short answer: run the code below. The first cell runs the actual fit, the second cell just prints and plots the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a0ad2-e2b6-4bbc-89b6-3de1500b2b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.makeSelection()\n",
    "fit = bayesmsd.lib.NPFit(data, motion_blur_f=1.)\n",
    "fitres = fit.run(show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c03dff2-3183-4575-a613-3afa4fe6c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit results:\")\n",
    "for key in sorted(fitres['params']):\n",
    "    print(f\"  {key:>15s} = {fitres['params'][key]}\")\n",
    "\n",
    "# Plot\n",
    "data.makeSelection()\n",
    "msd = nl.analysis.MSD(data)\n",
    "t_plot = np.arange(1, len(msd))\n",
    "plt.plot(dt*t_plot, msd[1:], label='data')\n",
    "\n",
    "msd = fit.MSD(fitres['params'], dt=t_plot)\n",
    "plt.plot(dt*t_plot, msd, color='r', label='fit')\n",
    "\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('time [sec]')\n",
    "plt.ylabel('MSD [μm²]')\n",
    "plt.title('MSD and its fit')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e92ab-8ab3-431f-94b0-67131ef9deca",
   "metadata": {},
   "source": [
    "Before getting into what exactly is happening here, let's do one more thing: the fit above gives us some parameter values, but we do not get error bars. Specifically: do you think the reported exponent is consistent with a Rouse model ($\\alpha = 0.5$)? Run the code below to find out!\n",
    "\n",
    "(*on my laptop this takes about two minutes to run*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566347d8-1ef8-403a-bf4e-8f668c8efb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler = bayesmsd.Profiler(fit, conf=0.95)\n",
    "mci = profiler.find_MCI(show_progress=True)\n",
    "\n",
    "print(\"Fit results with 95% credible intervals:\")\n",
    "for key in sorted(mci):\n",
    "    print(f\"  {key:>15s} = {mci[key][0]:.3g} [{mci[key][1][0]:.3g}, {mci[key][1][1]:.3g}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8cdfc-185f-4a75-9184-02d1db751a30",
   "metadata": {},
   "source": [
    "Looks like our data is consistent with a Rouse model!* Meaning: $\\alpha = 0.5$ is within the 95% credible interval. Note that this credible interval is still pretty broad; remember that we are analyzing data from a single nucleus.\n",
    "\n",
    "<font size=\"1\">\n",
    "*: Note that because the Rouse model is pretty simplistic, we don't actually have much of a reason to expect this in a biological system. But it's a fun observation.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c6ff6e-c097-4276-b00d-5ba2586fb4d3",
   "metadata": {},
   "source": [
    "### Huh? What just happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3403bb4d-99a6-4d99-894d-48568e5138c7",
   "metadata": {},
   "source": [
    "We applied some library functions without understanding what they do and got some results that I told you make sense. To understand what's going on, we will have to take a little dive into theory (yay!).\n",
    "\n",
    "(*we most likely will not have time to go through this during the workshop; if you want more details, come talk to me afterwards!*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a63ffab-bf5c-4051-809f-eb1585b133ed",
   "metadata": {},
   "source": [
    "Let's make two fundamental assumptions:\n",
    "\n",
    "1. **Gaussianity**\n",
    "   \n",
    "   The process generating our trajectories has Gaussian statistics. For our scenario here, this means that increments $x(t+\\Delta t) - x(t)$ are distributed as Gaussians (normal distributions).\n",
    "   \n",
    "2. **Increment stationarity**\n",
    "   \n",
    "   The increment correlation function\n",
    "   $$\n",
    "   C(\\tau_1, \\tau_2, t_1, t_2) \\equiv \\left\\langle \\left[ x(t_2+\\tau_2) - x(t_2) \\right]\\left[ x(t_1+\\tau_1) - x(t_1) \\right] \\right\\rangle\n",
    "   $$\n",
    "   does not depend on the absolute times $t_1$ and $t_2$, but only on the difference $\\Delta t \\equiv t_2-t_1$. We write $C(\\tau_1, \\tau_2, \\Delta t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4581c629-5e22-4cf0-928a-eb062105c1e7",
   "metadata": {},
   "source": [
    "Note how the expression for the increment correlation function is quite reminiscent of the expression for the MSD $\\psi(\\Delta t)$:\n",
    "$$\n",
    "\\psi(\\Delta t) \\equiv \\left\\langle \\left(x(t+\\Delta t) - x(t)\\right)^2 \\right\\rangle\\,.\n",
    "$$\n",
    "Indeed, by inspection you can see that\n",
    "$$\n",
    "\\psi(\\Delta t) = C(\\Delta t, \\Delta t, 0)\\,.\n",
    "$$\n",
    "So once we know the full increment correlation function, we can calculate the MSD as a special case. So far, this is not particularly surprising, since the increment correlation function is the more general object. Interestingly, however, under the assumption of increment stationarity (see above), we can also do the reverse:\n",
    "$$\n",
    "C(\\tau_1, \\tau_2, \\Delta t) = \\frac{1}{2}\\left[ \\psi(\\Delta t + \\tau_2) + \\psi(\\Delta t - \\tau_1) - \\psi(\\Delta t) - \\psi(\\Delta t + \\tau_2 - \\tau_1) \\right]\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39b93cc-5a00-4ebf-b213-29c5c3afb792",
   "metadata": {},
   "source": [
    "**Question 5**: Prove the relationship above. You can do this by writing $C$ and $\\psi$ in terms of expectation values of $x(t)$ and reformulating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a797041b-f85e-4dbe-b4a9-2f8c972203da",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<em>For an increment stationary process, the full increment correlation is fully determined by the\n",
    "MSD</em>. This increment correlation function can be viewed as the \"second moment\"* of the process; so <b>an increment stationary Gaussian process will be fully specified by this second moment, i.e. the MSD</b>.\n",
    "</div>\n",
    "\n",
    "This means we have a well-defined probability distribution over trajectories!\n",
    "\n",
    "<font size=\"1\">\n",
    "*: technically: second cumulant. But we usually assume zero mean (drift), so the distinction is moot.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dbc24c-4146-4a2f-a3ef-ecd8a89b2584",
   "metadata": {},
   "source": [
    "**Question 6**: Write down the probability distribution $P\\left(X\\mid\\psi\\right)$ of an increment stationary (and zero mean) Gaussian process with MSD $\\psi(\\Delta t)$. Here, $X \\equiv \\left( x(t_1), x(t_2), \\ldots, x(t_n) \\right)^T$ is the $n$-dimensional vector of positions at times $\\left\\lbrace t_1, t_2, \\ldots, t_n \\right\\rbrace$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628e79e5-bc8b-4b47-8c42-4daad93c4996",
   "metadata": {},
   "source": [
    "**Solution to Question 6**\n",
    "\n",
    "From the trajectory values $X$, we define the $n-1$ successive increments\n",
    "$$\n",
    "\\Delta X_i \\equiv x(t_{i+1}) - x(t_i)\\,.\n",
    "$$\n",
    "Now, the correlation matrix $\\Sigma$ of these increments is given by the increment correlation function and thus the MSD:\n",
    "\\begin{align}\n",
    "\\Sigma_{ij} {}\\equiv{}& \\left\\langle \\Delta X_i \\Delta X_j \\right\\rangle \\\\\n",
    "{}={}& \\left\\langle \\left[ x(t_{i+1}) - x(t_i) \\right]\\left[ x(t_{j+1}) - x(t_j) \\right] \\right\\rangle \\\\\n",
    "{}\\equiv{}& C\\left(t_{j+1} - t_j, t_{i+1} - t_i, t_i-t_j\\right) \\\\\n",
    "{}={}& \\frac{1}{2}\\left[ \\psi(t_{i+1} - t_j) + \\psi(t_i - t_{j+1}) - \\psi(t_i - t_j) - \\psi(t_{i+1} - t_{j+1}) \\right]\n",
    "\\end{align}\n",
    "This gives the correlation matrix; we will furthermore assume that $\\left\\langle \\Delta X_i \\right\\rangle = 0\\,\\forall i$, i.e. there is no drift in the particle motion. Then we can immediately write the full distribution over $X$ as the following multivariate Gaussian:\n",
    "$$\n",
    "P\\left(X\\mid\\psi\\right) = \\left|2\\pi\\Sigma\\right|^{-\\frac{1}{2}} \\exp\\left( -\\frac{1}{2}\\Delta X^T \\Sigma^{-1} \\Delta X \\right)\\,.\n",
    "$$\n",
    "\n",
    "<div style=\"text-align: right\"> $\\square$ </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e09d4-5e69-4dc5-86b2-2861cda02f14",
   "metadata": {},
   "source": [
    "Having an explicit expression for the *distribution over trajectories* $P\\left(X\\mid \\psi\\right)$ now allows us to do straight-forward Bayesian statistics with our data. Specifically, Bayes' law here reads\n",
    "$$\n",
    "P\\left(\\psi\\mid X\\right) = \\frac{P\\left(X\\mid \\psi\\right) P\\left(\\psi\\right)}{P\\left(X\\right)}\\,.\n",
    "$$\n",
    "In this expression, the left hand side $P\\left(\\psi\\mid X\\right)$ is the *posterior probability* for the MSD curve $\\psi$ given the observed data. On the right hand side, we have the *likelihood function* $P\\left(X\\mid \\psi\\right)$ and the *prior* $P\\left(\\psi\\right)$, as well as the *evidence* $P\\left(X\\right)$. The evidence is independent of $\\psi$ and thus serves mostly as normalization constant of the posterior; if we are interested in e.g. a *maximum a posterior* (MAP) estimate of the MSD curve, we can therefore ignore this term for the most part, leaving us with likelihood and prior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e85f893-9a12-4059-a70b-96a89dcf57c0",
   "metadata": {},
   "source": [
    "The likelihood function is the center piece of the machinery. We saw in Question 6 how we can evaluate this expression explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead3396-519e-48a7-9080-e758f7fb48d9",
   "metadata": {},
   "source": [
    "We therefore only need to discuss the prior $P(\\psi)$. This is a probability density over \"all MSD curves\", which is rather ill-defined. So we make this more precise by restricting&mdash;*a priori*&mdash;to MSD curves of certain shapes, like powerlaws or some model-based expression. The parameter space then reduces to a few scalar parameters, which we can usually infer with reasonable degrees of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b57e2b-e6c4-4ae4-a40d-c5dad8b962e1",
   "metadata": {},
   "source": [
    "**Example: powerlaw MSDs**. So far in this workshop, we have mostly considered MSDs of the shape\n",
    "$$\n",
    "\\psi(\\Delta t) = \\Gamma \\Delta t^\\alpha\\,,\n",
    "$$\n",
    "which are parametrized by an exponent $\\alpha$ and a prefactor $\\Gamma$ (sometimes referred to as \"anomalous diffusion constant\"). Gaussian processes with MSDs of this shape are known as *fractional Brownian motion* (fBm) and are one of the most popular models in the analysis of stochastic trajectories; to the extent that it is often taken as a given that MSDs should exhibit powerlaw behavior and the \"exponent\" $\\alpha$ is a useful quantity to report. It is worth keeping in mind that this is not necessarily true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2deb83-49e7-4376-8b81-d370d911c1c0",
   "metadata": {},
   "source": [
    "**Example: MSDs beyond simple powerlaws**. Consider two particles on a polymer; we track both and calculate the relative position of one with respect to the other. Under the Rouse model, the MSD of this process is given by two parameters $\\Gamma$ und $J$ and has the following form:\n",
    "$$\n",
    "\\psi(\\Delta t) = 2\\Gamma\\sqrt{\\Delta t}\\left[1 - \\exp\\left(-\\frac{J^2}{\\pi\\Gamma^2\\Delta t}\\right)\\right] + 2J \\,\\mathrm{erfc}\\sqrt{\\frac{J^2}{\\pi\\Gamma^2\\Delta t}} \\,.\n",
    "$$\n",
    "Note that from a statistical point of view, this expression is exactly as \"complicated\" than the powerlaw; both have two parameters to be inferred.\n",
    "\n",
    "<div style=\"text-align: right\"> $\\square$ </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27cd5c-e868-44a2-b1f8-b295021d1ac6",
   "metadata": {},
   "source": [
    "Once we settle on a useful parametric expression for the MSD, the Gaussian process likelihood and Bayes' law then allow us to calculate the (unnormalized) posterior, i.e. the probability density over the parameters given the data. Maximizing that expression gives a good point estimate; by exploring the posterior landscape around that maximum, we can give uncertainties on the estimates. These two steps are exactly what the `fit` and `profiler` objects do, respectively, in the code above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c09d8-f73d-48b8-9489-acee58d67a71",
   "metadata": {},
   "source": [
    "The described approach allows us to \"fit MSDs\" in a statistically rigorous way. Technically, this statement is actually somewhat misleading: we do not fit anything to the empirical MSD curve we calculate from the data. Instead, we fit a Gaussian process straight to those data; it just so happens that this Gaussian process is parametrized in terms of its MSD, which is thus a useful visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb13973-83af-4c5c-b772-c76b15967cba",
   "metadata": {},
   "source": [
    "**Note**: This logic also implies that any other second order statistic (e.g. velocity auto-correlation) is either equivalent to or contains less information than the MSD. This is the reason why MSDs are such a central object in trajectory analysis: given Gaussianity and suitable stationarity assumptions, the MSD contains full information about the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a7d1bf-0f8e-426e-b359-1d5f8d1842ca",
   "metadata": {},
   "source": [
    "**More info**: a comprehensive treatment of this logic is presented in Chapter 6 of [my PhD thesis](https://dspace.mit.edu/handle/1721.1/152570). Tutorials, examples, and full API reference for `bayesmsd` are [available at ReadTheDocs](https://bayesmsd.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822522e-5334-4cce-b865-dbd6eaf46404",
   "metadata": {},
   "source": [
    "## Trajectory-level heterogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60b51c-417c-4dfb-b6bb-0ba67c97acaf",
   "metadata": {},
   "source": [
    "Let's take another look at our empirical MSD plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f44c41-ab4c-4b5a-a8af-3f72db97eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.makeSelection()\n",
    "nl.plot.msd_overview(data, dt=dt, alpha=0.5) # useful shortcut\n",
    "\n",
    "plt.xlabel('time [sec]')\n",
    "plt.ylabel('MSD [μm²]')\n",
    "plt.ylim([1e-4, None])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d15b9b-a277-445a-a2f4-d5eec285d302",
   "metadata": {},
   "source": [
    "The MSD curves for the single trajectories (colored lines in the background) look like they all have a similar exponent; the prefactor, however (vertical offset in the log-plot) scatters across one order of magnitude. Is this just noise (we are looking at individual trajectories, after all) or is there actually some heterogeneity here? How could we assess this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde8a04c-350c-491a-8bcd-24c1aca1506b",
   "metadata": {},
   "source": [
    "Essentially, we would like to know what our data set would look like, if all the trajectories truly came from the same process. Fortunately, we have full information about this process, since we have the MSD. So we can just sample trajectories homogeneously from this process and cut them to match the real data in length and missing frames. This is what the following code does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c56fb-5b09-480d-8485-9fe65728572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit MSD of the real data\n",
    "fit = bayesmsd.lib.NPFit(data, motion_blur_f=1.)\n",
    "res = fit.run()\n",
    "\n",
    "# Generate homogeneous control data\n",
    "control = bayesmsd.gp.generate_dataset_like(data, (fit, res))\n",
    "\n",
    "# Plot!\n",
    "fig, axs = plt.subplots(1, 2, figsize=[10, 4], sharex=True, sharey=True)\n",
    "for ax, dat, title in zip(axs, [data, control], ['real data', 'homogeneous control']):\n",
    "    dat.makeSelection()\n",
    "    nl.plot.msd_overview(dat, ax=ax, dt=dt, alpha=0.5)\n",
    "\n",
    "    ax.set_xlabel('time [sec]')\n",
    "    ax.set_ylabel('MSD [μm²]')\n",
    "    ax.set_ylim([1e-4, None])\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba9011-d05d-4580-8078-923328660eb1",
   "metadata": {},
   "source": [
    "On the right, all trajectories are sampled from the same process. Because we have finite data, the single trajectories still scatter around the ensemble mean / true MSD. However, the scatter is noticeably less than in the real data. We conclude that chromatin motion in the (single!) nucleus in our movie is heterogeneous: some loci move faster than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee1c3c-d351-4601-823e-6ed15be379a5",
   "metadata": {},
   "source": [
    "**Question -1**: What makes chromatin loci move faster or slower?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
